---
---
@article{kollovieh2023assessing,
  abbr={ScoreAG},
  bibtex_show={true},
  title={Assessing Robustness via Score-Based Adversarial Image Generation},
  author={Kollovieh, Marcel and Gosch, Lukas and Scholten, Yan and Lienen, Marten and G{\"u}nnemann, Stephan},
  journal={arXiv preprint arXiv:2310.04285},
  year={2023},
  preview={ScoreAG.png},
  url={https://arxiv.org/pdf/2310.04285.pdf},
  pdf={https://arxiv.org/pdf/2310.04285.pdf},
}

@article{kollovieh2023predict,
  abbr={TSDiff},
  bibtex_show={true},
  %abstract={Diffusion models have achieved state-of-the-art performance in generative modeling tasks across various domains. Prior works on time series diffusion models have primarily focused on developing conditional models tailored to specific forecasting or imputation tasks. In this work, we explore the potential of task-agnostic, unconditional diffusion models for several time series applications. We propose TSDiff, an unconditionally trained diffusion model for time series. Our proposed self-guidance mechanism enables conditioning TSDiff for downstream tasks during inference, without requiring auxiliary networks or altering the training procedure. We demonstrate the effectiveness of our method on three different time series tasks: forecasting, refinement, and synthetic data generation. First, we show that TSDiff is competitive with several task-specific conditional forecasting methods (predict). Second, we leverage the learned implicit probability density of TSDiff to iteratively refine the predictions of base forecasters with reduced computational overhead over reverse diffusion (refine). Notably, the generative performance of the model remains intact -- downstream forecasters trained on synthetic samples from TSDiff outperform forecasters that are trained on samples from other state-of-the-art generative time series models, occasionally even outperforming models trained on real data (synthesize).},
  title={Predict, Refine, Synthesize: Self-Guiding Diffusion Models for Probabilistic Time Series Forecasting},
  author={Kollovieh*, Marcel and Ansari*, Abdul Fatir and Bohlke-Schneider, Michael and Zschiegner, Jasper and Wang, Hao and Wang, Yuyang},
  journal={Neural Information Processing Systems},
  year={2023},
  preview={TSDiff.png},
  url={https://arxiv.org/pdf/2307.11494.pdf},
  pdf={https://arxiv.org/pdf/2307.11494.pdf},
}

@article{kukavcka2021self,
  bibtex_show={true},
  %abstract={Fundus photography is the primary method for retinal imaging and essential for diabetic retinopathy prevention. Automated segmentation of fundus photographs would improve the quality, capacity, and cost-effectiveness of eye care screening programs. However, current segmentation methods are not robust towards the diversity in imaging conditions and pathologies typical for real-world clinical applications. To overcome these limitations, we utilized contrastive self-supervised learning to exploit the large variety of unlabeled fundus images in the publicly available EyePACS dataset. We pre-trained an encoder of a U-Net, which we later fine-tuned on several retinal vessel and lesion segmentation datasets. We demonstrate for the first time that by using contrastive self-supervised learning, the pre-trained network can recognize blood vessels, optic disc, fovea, and various lesions without being provided any labels. Furthermore, when fine-tuned on a downstream blood vessel segmentation task, such pre-trained networks achieve state-of-the-art performance on images from different datasets. Additionally, the pre-training also leads to shorter training times and an improved few-shot performance on both blood vessel and lesion segmentation tasks. Altogether, our results showcase the benefits of contrastive self-supervised pre-training which can play a crucial role in real-world clinical applications requiring robust models able to adapt to new devices with only a few annotated samples.},
  title={Self-Supervised Learning from Unlabeled Fundus Photographs Improves Segmentation of the Retina},
  author={Kuka{\v{c}}ka, Jan and Zenz, Anja and Kollovieh, Marcel and J{\"u}stel, Dominik and Ntziachristos, Vasilis},
  journal={Medical Imaging meets NeurIPS},
  year={2021},
  preview={SSRetinal.png},
  url={https://arxiv.org/pdf/2108.02798.pdf},
  pdf={https://arxiv.org/pdf/2108.02798.pdf},
}

@article{ezhov2021geometry,
  bibtex_show={true},
  %abstract={Modeling of brain tumor dynamics has the potential to advance therapeutic planning. Current modeling approaches resort to numerical solvers that simulate the tumor progression according to a given differential equation. Using highly-efficient numerical solvers, a single forward simulation takes up to a few minutes of compute. At the same time, clinical applications of tumor modeling often imply solving an inverse problem, requiring up to tens of thousands forward model evaluations when used for a Bayesian model personalization via sampling. This results in a total inference time prohibitively expensive for clinical translation. While recent data-driven approaches become capable of emulating physics simulation, they tend to fail in generalizing over the variability of the boundary conditions imposed by the patient-specific anatomy. In this paper, we propose a learnable surrogate for simulating tumor growth which maps the biophysical model parameters directly to simulation outputs, i.e. the local tumor cell densities, whilst respecting patient geometry. We test the neural solver on Bayesian tumor model personalization for a cohort of glioma patients. Bayesian inference using the proposed surrogate yields estimates analogous to those obtained by solving the forward model with a regular numerical solver. The near-real-time computation cost renders the proposed method suitable for clinical settings.},
  title={Geometry-aware neural solver for fast Bayesian calibration of brain tumor models},
  author={Ezhov, Ivan and Mot, Tudor and Shit, Suprosanna and Lipkova, Jana and Paetzold, Johannes C and Kofler, Florian and Pellegrini, Chantal and Kollovieh, Marcel and Navarro, Fernando and Li, Hongwei and others},
  journal={IEEE Transactions on Medical Imaging},
  volume={41},
  number={5},
  pages={1269--1278},
  year={2021},
  publisher={IEEE},
  preview={TumorGrowth.png},
  url={https://arxiv.org/pdf/2009.04240.pdf},
  pdf={https://arxiv.org/pdf/2009.04240.pdf},
}
